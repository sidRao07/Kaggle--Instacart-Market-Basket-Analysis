{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd7bc4ee6925ec87ebbae181e6628d011e440dde"
   },
   "source": [
    "Prediction of product reorder in an order<br>\n",
    "This code is based on the analysis done in clusterl<br>\n",
    "https://www.kaggle.com/paulantoine/light-gbm-benchmark-0-3692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "IDIR = '../input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b1acae3e7b876af8365a8745246f8bdb7adc662"
   },
   "outputs": [],
   "source": [
    "print('loading prior')\n",
    "priors = pd.read_csv(IDIR + 'order_products__prior.csv', dtype={\n",
    "            'order_id': np.int32,\n",
    "            'product_id': np.uint16,\n",
    "            'add_to_cart_order': np.int16,\n",
    "            'reordered': np.int8})\n",
    "\n",
    "print('loading train')\n",
    "train = pd.read_csv(IDIR + 'order_products__train.csv', dtype={\n",
    "            'order_id': np.int32,\n",
    "            'product_id': np.uint16,\n",
    "            'add_to_cart_order': np.int16,\n",
    "            'reordered': np.int8})\n",
    "\n",
    "print('loading orders')\n",
    "orders = pd.read_csv(IDIR + 'orders.csv', dtype={\n",
    "        'order_id': np.int32,\n",
    "        'user_id': np.int32,\n",
    "        'eval_set': 'category',\n",
    "        'order_number': np.int16,\n",
    "        'order_dow': np.int8,\n",
    "        'order_hour_of_day': np.int8,\n",
    "        'days_since_prior_order': np.float32})\n",
    "\n",
    "print('loading products')\n",
    "products = pd.read_csv(IDIR + 'products.csv', dtype={\n",
    "        'product_id': np.uint16,\n",
    "        'order_id': np.int32,\n",
    "        'aisle_id': np.uint8,\n",
    "        'department_id': np.uint8},\n",
    "        usecols=['product_id', 'aisle_id', 'department_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f652b80d3df1662b544a802ddf5f296b0ffdae1"
   },
   "outputs": [],
   "source": [
    "print('priors {}: {}'.format(priors.shape, ', '.join(priors.columns)))\n",
    "print('orders {}: {}'.format(orders.shape, ', '.join(orders.columns)))\n",
    "print('train {}: {}'.format(train.shape, ', '.join(train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd2dc98f97121316a00ea8bb5c46ad7519f90041"
   },
   "outputs": [],
   "source": [
    "print('computing product f')\n",
    "prods = pd.DataFrame()\n",
    "prods['orders'] = priors.groupby(priors.product_id).size().astype(np.int32)\n",
    "prods['reorders'] = priors['reordered'].groupby(priors.product_id).sum().astype(np.float32)\n",
    "prods['reorder_rate'] = (prods.reorders / prods.orders).astype(np.float32)\n",
    "products = products.join(prods, on='product_id')\n",
    "products.set_index('product_id', drop=False, inplace=True)\n",
    "del prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "640e00c29f81b0b5509e2fca39004a3c3ac9988a"
   },
   "outputs": [],
   "source": [
    "print('add order info to priors')\n",
    "orders.set_index('order_id', inplace=True, drop=False)\n",
    "priors = priors.join(orders, on='order_id', rsuffix='_')\n",
    "priors.drop('order_id_', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42f65b7be3e98dfe91ecf1586add7ffe0cc985b5"
   },
   "outputs": [],
   "source": [
    "print('computing user f')\n",
    "usr = pd.DataFrame()\n",
    "usr['average_days_between_orders'] = orders.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\n",
    "usr['nb_orders'] = orders.groupby('user_id').size().astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65a37a731f570c71c4851453c9c5ba2e8eb3fe7f"
   },
   "outputs": [],
   "source": [
    "users = pd.DataFrame()\n",
    "users['total_items'] = priors.groupby('user_id').size().astype(np.int16)\n",
    "users['all_products'] = priors.groupby('user_id')['product_id'].apply(set)\n",
    "users['total_distinct_items'] = (users.all_products.map(len)).astype(np.int16)\n",
    "users['user_max_order_num'] =  priors.groupby('user_id')['order_number'].max().astype(np.int16)\n",
    "users['total_buy_max'] =  priors.groupby(['user_id','product_id'])['product_id'].count().reset_index(level = 'user_id').reset_index(drop = True).groupby('user_id').max().astype(np.int16)\n",
    "users = users.join(usr) \n",
    "del usr\n",
    "users['average_basket'] = (users.total_items / users.nb_orders).astype(np.float32)\n",
    "print('user f', users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75b4962c348f1cba8e84390a976fe17add35d846"
   },
   "outputs": [],
   "source": [
    "print('compute userXproduct f - this is long...')\n",
    "priors['user_product'] = priors.product_id + priors.user_id * 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad2bace8251c2e8ca578859df168851dae1dd2ab"
   },
   "outputs": [],
   "source": [
    "d= dict()\n",
    "for row in priors.itertuples():\n",
    "    z = row.user_product\n",
    "    if z not in d:\n",
    "        d[z] = (1,\n",
    "                (row.order_number, row.order_id),\n",
    "                (row.order_number, row.order_id),\n",
    "                row.add_to_cart_order)\n",
    "    else:\n",
    "        d[z] = (d[z][0] + 1,\n",
    "                max(d[z][1], (row.order_number, row.order_id)),\n",
    "                min(d[z][2], (row.order_number, row.order_id)),\n",
    "                d[z][3] + row.add_to_cart_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c4a6a60e6cc57dee80c06d691b16229467b140e"
   },
   "outputs": [],
   "source": [
    "print('to dataframe (less memory)')\n",
    "userXproduct = pd.DataFrame.from_dict(d, orient='index')\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b29250f1bf2a676f4283484f402251f8b49dcedb"
   },
   "outputs": [],
   "source": [
    "userXproduct.columns = ['nb_orders', 'last_order_id','first_order_number', 'sum_pos_in_cart']\n",
    "userXproduct.nb_orders = userXproduct.nb_orders.astype(np.int16)\n",
    "userXproduct.last_order_id = userXproduct.last_order_id.map(lambda x: x[1]).astype(np.int32)\n",
    "userXproduct.first_order_number = userXproduct.first_order_number.map(lambda x: x[0]).astype(np.int16)\n",
    "userXproduct.sum_pos_in_cart = userXproduct.sum_pos_in_cart.astype(np.int16)\n",
    "print('user X product f', len(userXproduct))\n",
    "\n",
    "userXproduct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df18ea9bc8100ef77ce443685ee2220a0b325157"
   },
   "outputs": [],
   "source": [
    "del priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79140b7affd6dc6637dca4f03052589a962ea406"
   },
   "outputs": [],
   "source": [
    "print('split orders : train, test')\n",
    "test_orders = orders[orders.eval_set == 'test']\n",
    "train_orders = orders[orders.eval_set == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3700b529a84e84391673fe8dd68b3b0a3000a525"
   },
   "outputs": [],
   "source": [
    "train.set_index(['order_id', 'product_id'], inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ab3eadc8b51870ff68c768e6a43cd82db17ba5c"
   },
   "outputs": [],
   "source": [
    "def features(selected_orders, labels_given=False):\n",
    "    print('build candidate list')\n",
    "    order_list = []\n",
    "    product_list = []\n",
    "    labels = []\n",
    "    i=0\n",
    "    for row in selected_orders.itertuples():\n",
    "        i+=1\n",
    "        if i%10000 == 0: print('order row',i)\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        user_products = users.all_products[user_id]\n",
    "        product_list += user_products\n",
    "        order_list += [order_id] * len(user_products)\n",
    "        if labels_given:\n",
    "            labels += [(order_id, product) in train.index for product in user_products]\n",
    "        \n",
    "    df = pd.DataFrame({'order_id':order_list, 'product_id':product_list}, dtype=np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    del product_list\n",
    "    \n",
    "    print('user related features')\n",
    "    df['user_id'] = df.order_id.map(orders.user_id)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "    df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "    df['total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "    df['user_average_basket'] =  df.user_id.map(users.average_basket)\n",
    "    df['user_total_buy_max'] = df.user_id.map(users.total_buy_max).astype(np.int16)\n",
    "    \n",
    "    print('order related features')\n",
    "    df['order_dow'] = df.order_id.map(orders.order_dow)\n",
    "    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "    df['days_since_ratio'] = (df.days_since_prior_order / df.user_average_days_between_orders).map(lambda x: 0 if math.isnan(x) else x).astype(np.float32)\n",
    "    \n",
    "    print('product related features')\n",
    "    df['aisle_id'] = df.product_id.map(products.aisle_id)\n",
    "    df['department_id'] = df.product_id.map(products.department_id)\n",
    "    df['product_orders'] = df.product_id.map(products.orders).astype(np.int32)\n",
    "    df['product_reorders'] = df.product_id.map(products.reorders)\n",
    "    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate).astype(np.float32)\n",
    "\n",
    "    print('user_X_product related features')\n",
    "    df['z'] = df.user_id * 100000 + df.product_id\n",
    "    df.drop(['user_id'], axis=1, inplace=True)\n",
    "    df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n",
    "    df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n",
    "    df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_pos_in_cart) / df.UP_orders).astype(np.float32)\n",
    "    df['UP_reorder_rate'] = ((df.UP_orders-1) / (df.user_total_orders-1).astype(np.float32))\n",
    "    df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_id.map(orders.order_number)\n",
    "    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - df.UP_last_order_id.map(orders.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n",
    "    df['UP_delta_dow_vs_last'] = abs(df.order_dow - df.UP_last_order_id.map(orders.order_dow)).map(lambda x: min(x, 7-x)).astype(np.int8)\n",
    "    df['UP_drop_chance'] = (df.user_total_orders - df.UP_last_order_id.map(orders.order_number)).astype(np.float)\n",
    "    df['UP_chance_vs_bought'] = (df.user_total_orders - df.z.map(userXproduct.first_order_number)).astype(np.float32)\n",
    "    df['UP_chance'] = (df.UP_orders - 1)/(df.user_total_orders - df.z.map(userXproduct.first_order_number)).astype(np.float32)\n",
    "    df['UP_chance_ratio'] = (1/(df.user_total_orders - df.UP_last_order_id.map(orders.order_number)) - (df.UP_orders - 1)/(df.user_total_orders - df.z.map(userXproduct.first_order_number))).astype(np.float32)\n",
    "    df.drop(['UP_last_order_id','z'], axis=1, inplace=True)\n",
    "    df.drop(['order_id','product_id'], axis=1)\n",
    "    print(df.dtypes)\n",
    "    print(df.memory_usage())\n",
    "    return (df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8dd3edf52353d49664f6ef4ffb6cbae4e16d7be9"
   },
   "outputs": [],
   "source": [
    "df_train, labels = features(train_orders, labels_given=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a980ecd4412793c5f61fd4e04d7651c21b04c66"
   },
   "outputs": [],
   "source": [
    "features_to_use = ['user_total_orders', 'user_total_items',\n",
    "       'total_distinct_items', 'user_average_days_between_orders',\n",
    "       'user_average_basket', 'order_dow',\n",
    "       'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "       'department_id', 'product_orders', 'product_reorders',\n",
    "       'product_reorder_rate', 'UP_orders', 'UP_orders_ratio',\n",
    "       'UP_average_pos_in_cart', 'UP_reorder_rate', 'UP_orders_since_last',\n",
    "       'UP_delta_hour_vs_last', 'UP_delta_dow_vs_last', 'UP_drop_chance',\n",
    "       'UP_chance_vs_bought', 'user_total_buy_max', 'UP_chance', 'UP_chance_ratio','aisle_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d15f3944df029a300909352972f3ead2d899212"
   },
   "outputs": [],
   "source": [
    "#Dividing into train and cv for selecting best parameters\n",
    "d_train, d_cv, l_train, l_cv = train_test_split(df_train, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7458c84836b3cf45cd3d918f18ba01d0e105312"
   },
   "outputs": [],
   "source": [
    "print('formating for lgb')\n",
    "d_train_gbm = lgb.Dataset(d_train[features_to_use],\n",
    "                      label=l_train,\n",
    "                      categorical_feature=['aisle_id', 'department_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1cfef7c3e1647c9b0e4593c262876a5559d2907b"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "#     'num_leaves': 96,\n",
    "#     'max_depth': 10,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'bagging_fraction': 0.95,\n",
    "#     'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0609c6e09e7a438da57e72dc88b499a8d0b8812d"
   },
   "outputs": [],
   "source": [
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params, d_train_gbm, ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebee54da1058171e11c3821467f488b19bd7a036"
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "633138e0aa5a32daea8b8c5e2694cc91f8f9f9a5"
   },
   "outputs": [],
   "source": [
    "#Checking on CV\n",
    "print('light GBM predict')\n",
    "preds = bst.predict(d_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a370fdcf0b0a7ef1d7b05c907f47ae4b4e05a2c4"
   },
   "outputs": [],
   "source": [
    "d_cv['pred'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bc33ab2ab04b2ae790e4c6ef2391800924d2050"
   },
   "outputs": [],
   "source": [
    "d_cv['given_label'] = l_cv\n",
    "d_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08c6b3315c4c20ab65093f7f9cb107c66dfd98da"
   },
   "outputs": [],
   "source": [
    "#Creating dataframe of given products\n",
    "given_prods = {}\n",
    "for row in d_cv.itertuples():\n",
    "    if row.given_label == 1:\n",
    "        try:\n",
    "            given_prods[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            given_prods[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in d_cv.order_id:\n",
    "    if order not in given_prods:\n",
    "        given_prods[order] = 'None'\n",
    "\n",
    "#Creating dataframe of given products\n",
    "given_prods = pd.DataFrame.from_dict(given_prods, orient='index')\n",
    "given_prods.reset_index(inplace=True)\n",
    "given_prods.columns = ['order_id','products']\n",
    "#print(given_prods.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "874f8219e3491028720ba070e74b01f4e623bf47"
   },
   "outputs": [],
   "source": [
    "#Eval function\n",
    "def eval_fun(labels, preds):\n",
    "    labels = labels.split(' ')\n",
    "    preds = preds.split(' ')\n",
    "    rr = (np.intersect1d(labels, preds))\n",
    "    precision = np.float(len(rr)) / len(preds)\n",
    "    recall = np.float(len(rr)) / len(labels)\n",
    "    try:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        return (precision, recall, 0.0)\n",
    "    return (precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6924e299efbae9dc5ab0aac2083556dfc131ec0"
   },
   "outputs": [],
   "source": [
    "##Creating label column based on thresold\n",
    "thresold = 0.5\n",
    "f1_scores=[]\n",
    "for t in thresold:\n",
    "    d_cv['pred_label'] = np.where(d_cv['pred'] > t, 1, 0)\n",
    "\n",
    "    #Creating dataframe of predicted products\n",
    "    pred_prods = {}\n",
    "    for row in d_cv.itertuples():\n",
    "        if row.pred_label == 1:\n",
    "            try:\n",
    "                pred_prods[row.order_id] += ' ' + str(row.product_id)\n",
    "            except:\n",
    "                pred_prods[row.order_id] = str(row.product_id)\n",
    "\n",
    "    for order in d_cv.order_id:\n",
    "        if order not in pred_prods:\n",
    "            pred_prods[order] = 'None'\n",
    "\n",
    "    #Creating dataframe of predicted products\n",
    "    pred_prods = pd.DataFrame.from_dict(pred_prods, orient='index')\n",
    "    pred_prods.reset_index(inplace=True)\n",
    "    pred_prods.columns = ['order_id','products']\n",
    "    #print(pred_prods.head())\n",
    "\n",
    "    #Merging predicted and given\n",
    "    merge_eval = pd.merge(pred_prods, given_prods, how='inner', on='order_id')\n",
    "    #print(merge_eval.head())\n",
    "\n",
    "    res = list()\n",
    "    for entry in merge_eval.itertuples():\n",
    "        res.append(eval_fun(entry[2], entry[3]))\n",
    "\n",
    "    res = pd.DataFrame(np.array(res), columns=['precision', 'recall', 'f1'])\n",
    "    #print(res.head())\n",
    "\n",
    "    f1_score = np.mean(res['f1'])\n",
    "\n",
    "    f1_scores.append(f1_score)\n",
    "\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b9d0c5fe3a7b74609c3ff6ad6af5df242e965d7c"
   },
   "source": [
    "### Best Features\n",
    "We obtain the best accuracy when we train on all the features \n",
    "\n",
    "### Best Parameters\n",
    "number of leaves: 96(keeps on increasing so limiting)<br>\n",
    "depth: 10<br>\n",
    "feature fraction: 0.85 (0.4855)<br>\n",
    "bagging fraction: 0.75 (0.4856)<br>\n",
    "bagging frequency: 5<br>\n",
    "learning rate: 0.01<br>\n",
    "rounds: 100<br>\n",
    "\n",
    "#### Please Note:\n",
    "These are the best values of parameters we have obtained after looping through range of values for each parameter. <br>\n",
    "We obtain a frequency of 36.4%(public) on these parameter, if we use the parameters originallly mentioned in the reference code, we get an accuracy of 38.09%(public). <br>\n",
    "$\\therefore$ we shall go ahead with the parameter mentioned in the reference code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7dba3409022e220c81e5f6307161d0345e43ba6f"
   },
   "source": [
    "### Predicting on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50ec923813d07b5246bf5eda923710fe5972dcce"
   },
   "outputs": [],
   "source": [
    "d_train_bst = lgb.Dataset(df_train[features_to_use],\n",
    "                      label=labels,\n",
    "                      categorical_feature=['aisle_id', 'department_id'])  # , 'order_hour_of_day', 'dow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d422f93261429c6763e021c9036727c69760b7e6"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'max_depth': 10,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9bd758393e0ac62e918f81cfb0449e915cbfe223"
   },
   "outputs": [],
   "source": [
    "print('light GBM train :-)')\n",
    "bst2 = lgb.train(params, d_train_bst, ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67df2d90ecd75427357547ba9beb15e5c9e07ff9"
   },
   "outputs": [],
   "source": [
    "#Predicting on test\n",
    "df_test, _ = features(test_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ad6e2dd9bab2984e1270f98a183c1dbaffc6840",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('light GBM predict')\n",
    "preds = bst2.predict(df_test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e38d65aa81869515f49594752d19751a7d73a50a"
   },
   "outputs": [],
   "source": [
    "df_test['pred'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61cd587c4e020c0d4c64251ed022d53c209a8008"
   },
   "outputs": [],
   "source": [
    "del df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f86f4bfa5005f86fbe476db98154c7c5787f9855"
   },
   "outputs": [],
   "source": [
    "##Writing a function to generate f-score by giving threshold and top n features\n",
    "#n_features = 10\n",
    "def gbm_tune(n_features, thresold):\n",
    "    \n",
    "    feat_imp=[]\n",
    "    for i in range(0,n_features):\n",
    "        feat_imp.append(imp_features[i][0])\n",
    "        \n",
    "    #Formatting for lgbm (best features)\n",
    "    if n_features==26:\n",
    "        d_train_ftune = lgb.Dataset(d_train[feat_imp], label=l_train, categorical_feature=['aisle_id','department_id'])\n",
    "    else:\n",
    "        d_train_ftune = lgb.Dataset(d_train[feat_imp], label=l_train, categorical_feature=['aisle_id',])\n",
    "    \n",
    "    #lgbm training for best features\n",
    "    lgbc_ftune = lgb.train(params, d_train_ftune, ROUNDS)\n",
    "    \n",
    "    #Predicting\n",
    "    d_cv_ftune = d_cv[feat_imp]\n",
    "    pred_gbm = lgbc_ftune.predict(d_cv_ftune)\n",
    "    d_cv['pred'] = pred_gbm\n",
    "    #print('test:',d_cv_ftune.head())\n",
    "    \n",
    "    ##Creating label column based on thresold\n",
    "    #thresold = 0.5\n",
    "    d_cv['pred_label'] = np.where(d_cv['pred'] > thresold, 1, 0)\n",
    "        \n",
    "    #Creating dataframe of predicted products\n",
    "    pred_prods = {}\n",
    "    for row in d_cv.itertuples():\n",
    "        if row.pred_label == 1:\n",
    "            try:\n",
    "                pred_prods[row.order_id] += ' ' + str(row.product_id)\n",
    "            except:\n",
    "                pred_prods[row.order_id] = str(row.product_id)\n",
    "    \n",
    "    for order in d_cv.order_id:\n",
    "        if order not in pred_prods:\n",
    "            pred_prods[order] = 'None'\n",
    "            \n",
    "    #Creating dataframe of predicted products\n",
    "    pred_prods = pd.DataFrame.from_dict(pred_prods, orient='index')\n",
    "    pred_prods.reset_index(inplace=True)\n",
    "    pred_prods.columns = ['order_id','products']\n",
    "    #print(pred_prods.head())\n",
    "    \n",
    "    #Merging predicted and given\n",
    "    merge_eval = pd.merge(pred_prods, given_prods, how='inner', on='order_id')\n",
    "    #print(merge_eval.head())\n",
    "    \n",
    "    res = list()\n",
    "    for entry in merge_eval.itertuples():\n",
    "        res.append(eval_fun(entry[2], entry[3]))\n",
    "    \n",
    "    res = pd.DataFrame(np.array(res), columns=['precision', 'recall', 'f1'])\n",
    "    #print(res.head())\n",
    "    \n",
    "    f1_score = np.mean(res['f1'])\n",
    "    \n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9734b94462734fc6187e942faee897a03de0021a"
   },
   "outputs": [],
   "source": [
    "# #Plotting for n-features vs f1-score\n",
    "# thresold = [0.2,0.22,0.3,0.35,0.4,0.5,0.55]\n",
    "# f1_scores = []\n",
    "# for t in thresold:\n",
    "#     f1 = gbm_tune(26,t)\n",
    "#     print('t',t)\n",
    "#     print('f1',f1)\n",
    "#     f1_scores.append(f1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8fe0712cca2adcc43f3db8f817ca18aad06f6bbb"
   },
   "outputs": [],
   "source": [
    "# plt.plot(thresold,f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0fca18e5e6ed857d4614a0543ed8f30ff861dbe1"
   },
   "outputs": [],
   "source": [
    "# TRESHOLD = 0.35 #Obtained using CV dataset\n",
    "# d = dict()\n",
    "# for row in df_test.itertuples():\n",
    "#     if row.pred > TRESHOLD:\n",
    "#         try:\n",
    "#             d[row.order_id] += ' ' + str(row.product_id)\n",
    "#         except:\n",
    "#             d[row.order_id] = str(row.product_id)\n",
    "\n",
    "# for order in test_orders.order_id:\n",
    "#     if order not in d:\n",
    "#         d[order] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6fccbaf480cc95c97f2acdd8b39125961146ceb2"
   },
   "outputs": [],
   "source": [
    "# sub = pd.DataFrame.from_dict(d, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b593d388fb50232ab930f2b8d6a202eb8713de7"
   },
   "outputs": [],
   "source": [
    "# #First submission\n",
    "# sub.reset_index(inplace=True)\n",
    "# sub.columns = ['order_id', 'products']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9939262e1e7f68ce9714ed45e77e221fe9ab51a9"
   },
   "outputs": [],
   "source": [
    "# sub.to_csv('sub0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2bdffc0f5985858f1ddb14cf6d6f30356ede13c"
   },
   "outputs": [],
   "source": [
    "TRESHOLD = 0.22 #Obtained using CV dataset\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > TRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa60939ec9bc6cb9c24256897b385ad118f5a257"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(d, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "94e7612059b72edd33805bd41f8f59ae11aeaac8"
   },
   "outputs": [],
   "source": [
    "#First submission\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51d22e21e2b572f38eb4f73e04793663b35e324c"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('sub_LGBM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d7b80152012ed086ddd467e8e8ea6f7d8507c62"
   },
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "19b2b5acff0fe581b04fcf523fb6763ebc3a8c54"
   },
   "source": [
    "### Selecting top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e4f5b7c2602a0d5ecc500af828e038bd4afb9ed"
   },
   "outputs": [],
   "source": [
    "feature_names = list(bst.feature_name())\n",
    "feature_importances = list(bst.feature_importance())\n",
    "print(len(feature_names))\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3502a6583ba937ff5716659333f84bce3c777d9c"
   },
   "outputs": [],
   "source": [
    "#Assigning features to importance\n",
    "imp_features = []\n",
    "for i,j  in zip(feature_names, feature_importances):\n",
    "    imp_features.append((i,j))\n",
    "\n",
    "#Sort on the basis of the importance\n",
    "imp_features.sort(key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "imp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60a56286a26cc30f25a71063dddda022c6756b44"
   },
   "outputs": [],
   "source": [
    "# #Plotting for n-features vs f1-score\n",
    "# n_top_features = [5,10,15,20,25]\n",
    "# f1_scores = []\n",
    "# for n in n_top_features:\n",
    "#     f1 = gbm_tune(n,0.22)\n",
    "#     print('f1',f1)\n",
    "#     print('n',n)\n",
    "#     f1_scores.append(f1)\n",
    "    \n",
    "# plt.plot(n_top_features,f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a5d7e38659ccda261ce2e4a3e10cc4ee981ef03"
   },
   "source": [
    "$\\therefore$ best f1-score is obtained when all the features are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d95706f6643fa8e12ae30ad5520467e8b4d0a98"
   },
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d9b719c2ff36f591ed8c47fbf028af85e81936a"
   },
   "outputs": [],
   "source": [
    "# ##Grid Search to find best parameters\n",
    "# f1_scores=[]\n",
    "# #num_leaves = [60,96,120,200,500]\n",
    "# #max_depth = [7,10,20,-1]\n",
    "# #feature_fraction = [0.7,0.75,0.80,0.85,0.90,0.95]\n",
    "# #bagging_fraction = [0.7,0.75,0.80,0.85,0.90,0.95,1.0]\n",
    "# # bagging_freq = [1,5,10,20,100]\n",
    "# # learning_rate = [0.001,0.005,0.01]\n",
    "# rounds=[10,50,100,500]\n",
    "\n",
    "# #for l in num_leaves:\n",
    "# #for m in max_depth:\n",
    "# #for f in feature_fraction:\n",
    "# # for b in bagging_fraction:\n",
    "# # for bf in bagging_freq:\n",
    "# # for lr in learning_rate:\n",
    "# for r in rounds:\n",
    "#     params = {\n",
    "#         'learning_rate': [lr],\n",
    "#         'num_leaves': [96],\n",
    "#         'boosting_type' : ['gbdt'],\n",
    "#         'objective' : ['binary'],\n",
    "#         'max_depth': 10,\n",
    "#         'feature_fraction': 0.85,\n",
    "#         'bagging_fraction': 0.75,\n",
    "#         'bagging_freq': 5\n",
    "#     }\n",
    "    \n",
    "#     #Formatting for lgbm(Best params)\n",
    "#     d_train_ptune = lgb.Dataset(d_train[features_to_use], label=l_train, categorical_feature=['aisle_id','department_id'])\n",
    "    \n",
    "#     #lgbm training for best params\n",
    "#     lgbc_ptune = lgb.train(params, d_train_ptune, r)\n",
    "    \n",
    "#     #Predicting\n",
    "#     d_cv_ptune = d_cv[features_to_use]\n",
    "#     pred_gbm = lgbc_ptune.predict(d_cv_ptune)\n",
    "#     d_cv['pred'] = pred_gbm\n",
    "    \n",
    "#     ##Creating label column based on thresold\n",
    "#     d_cv['pred_label'] = np.where(d_cv['pred'] > 0.22, 1, 0)\n",
    "    \n",
    "#     pred_prods = {}\n",
    "#     for row in d_cv.itertuples():\n",
    "#         if row.pred_label == 1:\n",
    "#             try:\n",
    "#                 pred_prods[row.order_id] += ' ' + str(row.product_id)\n",
    "#             except:\n",
    "#                 pred_prods[row.order_id] = str(row.product_id)\n",
    "    \n",
    "#     for order in d_cv.order_id:\n",
    "#         if order not in pred_prods:\n",
    "#             pred_prods[order] = 'None'\n",
    "            \n",
    "#     #Creating dataframe of predicted products\n",
    "#     pred_prods = pd.DataFrame.from_dict(pred_prods, orient='index')\n",
    "#     pred_prods.reset_index(inplace=True)\n",
    "#     pred_prods.columns = ['order_id','products']\n",
    "    \n",
    "#     merge_eval = pd.merge(pred_prods, given_prods, how='inner', on='order_id')\n",
    "#     #print(merge_eval.head())\n",
    "    \n",
    "#     res = list()\n",
    "#     for entry in merge_eval.itertuples():\n",
    "#         res.append(eval_fun(entry[2], entry[3]))\n",
    "    \n",
    "#     res = pd.DataFrame(np.array(res), columns=['precision', 'recall', 'f1'])\n",
    "#     #print(res.head())\n",
    "    \n",
    "#     f1_score = np.mean(res['f1'])\n",
    "    \n",
    "#     f1_scores.append(f1_score)\n",
    "    \n",
    "# print('f1 scores:',f1_scores)\n",
    "# #plt.plot(num_leaves,f1_scores)\n",
    "# #plt.plot(max_depth,f1_scores)\n",
    "# #plt.plot(feature_fraction,f1_scores)\n",
    "# # plt.plot(bagging_fraction,f1_scores)\n",
    "# # plt.plot(learning_rate,f1_scores)\n",
    "# plt.plot(rounds,f1_scores)\n",
    "\n",
    "# plt.xlabel('rounds')\n",
    "# plt.ylabel('f-score')\n",
    "# plt.title('f-score vs rounds')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "668551c3f0c915e994327df0636160ed90fb147e"
   },
   "outputs": [],
   "source": [
    "##Best Parameters\n",
    "# number of leaves: 96(keeps on increasing so limiting)\n",
    "# depth: 10\n",
    "# feature fraction: 0.85 (0.4855)\n",
    "# bagging fraction: 0.75 (0.4856)\n",
    "# bagging frequency: 5\n",
    "# learning rate: 0.01\n",
    "# rounds=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8155b085064ac0292da97c32af7e118b1056276"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e8769556ce752c5c45d8e9ec14f4f5b4be247c7"
   },
   "outputs": [],
   "source": [
    "# #Training GBM model for Grid Search\n",
    "# grd_cv = lgb.LGBMClassifier(boosting_type= 'gbdt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aff3cb2e098b37ac3f638057d2622999f9e393e3"
   },
   "outputs": [],
   "source": [
    "# # #Creating the grid\n",
    "# gridCV = GridSearchCV(grd_cv, gridParams,\n",
    "#                       verbose=0,\n",
    "#                       cv=4,\n",
    "#                       n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1717ecbafe3f563031fd3be2340a4c265d87f1ea"
   },
   "outputs": [],
   "source": [
    "# # #Running the Grid\n",
    "# gridCV.fit(d_train, l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de68bc58323e80753d52f7a4d7fcdb82356c2d3e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0b6aea0cfedcb0ab4cc7b8f39c7d3c47336fd6f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c0f114611047e16bbbdafe88a0a5730e21aa8ca"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aa8101953e71cd63028aa94a347c773ff3b2bae4"
   },
   "outputs": [],
   "source": [
    "f1_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
